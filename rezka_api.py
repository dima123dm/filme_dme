import os
import re
import time
from curl_cffi import requests as curl_requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv

load_dotenv()

class RezkaClient:
    def __init__(self):
        self.session = curl_requests.Session(impersonate="chrome110")
        self.login = os.getenv("REZKA_LOGIN")
        self.password = os.getenv("REZKA_PASS")
        self.is_logged_in = False
        self.origin = "https://hdrezka.me"

    def auth(self):
        if self.is_logged_in: return True
        try:
            print("üîë Auth...")
            headers = {"X-Requested-With": "XMLHttpRequest"}
            r = self.session.post(f"{self.origin}/ajax/login/", 
                                data={"login_name": self.login, "login_password": self.password},
                                headers=headers)
            if r.json().get('success'):
                self.is_logged_in = True
                print("‚úÖ Auth Success")
                return True
        except: pass
        return False

    def _is_watched_check(self, tag):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≥–∞–ª–æ—á–∫—É –≤–µ–∑–¥–µ"""
        if not tag: return False
        classes = tag.get("class", [])
        if "watched" in classes or "b-watched" in classes: return True
        
        # –ò—â–µ–º –∏–∫–æ–Ω–∫—É –≤–Ω—É—Ç—Ä–∏
        icon = tag.find(class_=lambda x: x and ("watch-episode-action" in x or "b-ico" in x))
        if icon:
            icon_classes = icon.get("class", [])
            if "watched" in icon_classes or "b-watched" in icon_classes: return True
        return False

    def _parse_schedule_table(self, soup):
        """–ü–∞—Ä—Å–∏—Ç —Ç–∞–±–ª–∏—Ü—É. –§–ò–õ–¨–¢–†–£–ï–¢ –ë–£–î–£–©–ò–ï –°–ï–†–ò–ò."""
        seasons = {}
        table = soup.find("table", class_="b-post__schedule_table")
        if not table: return {}

        rows = table.find_all("tr")
        for tr in rows:
            td_1 = tr.find(class_="td-1")
            if not td_1: continue
            
            text = td_1.text.strip()
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–Ω—è—Ç—å –Ω–æ–º–µ—Ä —Å–µ–∑–æ–Ω–∞ –∏ —Å–µ—Ä–∏–∏
            s_id = "1"
            e_id = "1"
            
            match = re.search(r'(\d+)\s*—Å–µ–∑–æ–Ω\s*(\d+)\s*—Å–µ—Ä–∏—è', text)
            if match:
                s_id = match.group(1)
                e_id = match.group(2)
            else:
                match_ep = re.search(r'(\d+)\s*—Å–µ—Ä–∏—è', text)
                if match_ep: e_id = match_ep.group(1)
            
            # --- –ì–õ–ê–í–ù–´–ô –§–ò–õ–¨–¢–† ---
            # 1. –ò—â–µ–º ID –≤–∏–¥–µ–æ. –ï—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç - —Å–µ—Ä–∏—è –µ—â–µ –Ω–µ –≤—ã—à–ª–∞.
            global_id = td_1.get("data-id")
            action_icon = tr.find(class_="watch-episode-action")
            
            if action_icon and action_icon.get("data-id"):
                global_id = action_icon.get("data-id")
            
            # –ï—Å–ª–∏ ID –≤—Å—ë –µ—â–µ –Ω–µ—Ç - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (—ç—Ç–æ –±—É–¥—É—â–∞—è —Å–µ—Ä–∏—è)
            if not global_id:
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
            is_watched = False
            if action_icon and "watched" in action_icon.get("class", []):
                is_watched = True
            elif self._is_watched_check(tr):
                is_watched = True

            if s_id not in seasons: seasons[s_id] = []
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
            exists = False
            for ep in seasons[s_id]:
                if ep['episode'] == e_id: exists = True
            
            if not exists:
                seasons[s_id].append({
                    "title": text, "episode": e_id, 
                    "global_id": global_id, "watched": is_watched
                })
        return seasons

    def _parse_html_list(self, html_content):
        soup = BeautifulSoup(html_content, 'html.parser')
        seasons = {}
        items = soup.find_all("li", class_="b-simple_episode__item")
        
        for item in items:
            try:
                s_id = item.get("data-season_id", "1")
                e_id = item.get("data-episode_id", "1")
                title = item.text.strip()
                global_id = item.get("data-id")
                if not global_id:
                    inner = item.find(attrs={"data-id": True})
                    if inner: global_id = inner.get("data-id")

                is_watched = self._is_watched_check(item)

                if s_id not in seasons: seasons[s_id] = []
                seasons[s_id].append({
                    "title": title, "episode": e_id, 
                    "global_id": global_id, "watched": is_watched
                })
            except: continue
        return seasons

    def get_series_details(self, url):
        if not self.auth(): return {"error": "Auth failed"}
        try:
            print(f"üîé {url}")
            r = self.session.get(url)
            soup = BeautifulSoup(r.text, 'html.parser')
            
            hq_poster = ""
            side = soup.find(class_="b-sidecover")
            if side:
                if side.find('a'): hq_poster = side.find('a').get('href')
                elif side.find('img'): hq_poster = side.find('img').get('src')

            post_id = None
            if soup.find(id="post_id"): post_id = soup.find(id="post_id").get("value")
            else:
                match = re.search(r'["\']post_id["\']\s*:\s*(\d+)', r.text)
                if match: post_id = match.group(1)

            # 1. –¢–ê–ë–õ–ò–¶–ê (–£–∂–µ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –±—É–¥—É—â–∏—Ö —Å–µ—Ä–∏–π)
            table_seasons = self._parse_schedule_table(soup)
            
            # 2. –ü–õ–ï–ï–† (–°–±–æ—Ä—â–∏–∫ —Å–µ–∑–æ–Ω–æ–≤)
            player_seasons = {}
            if post_id:
                translator_id = None
                active = soup.find(class_="b-translator__item active")
                if active: translator_id = active.get("data-translator_id")
                else:
                    match = re.search(r'["\']translator_id["\']\s*:\s*(\d+)', r.text)
                    if match: translator_id = match.group(1)

                # --- –õ–û–ì–ò–ö–ê –ü–û–ò–°–ö–ê ID –°–ï–ó–û–ù–û–í ---
                season_ids = []
                
                # –ò—â–µ–º –≤–∫–ª–∞–¥–∫–∏ (li)
                tabs = soup.select(".b-simple_episode__seasons-item")
                for t in tabs:
                    # –í–ê–ñ–ù–û: –ë–µ—Ä–µ–º data-tab_id, –∞ –Ω–µ data-id (data-id —ç—Ç–æ ID –ø–æ—Å—Ç–∞!)
                    sid = t.get("data-tab_id")
                    if sid: season_ids.append(sid)
                
                # –ï—Å–ª–∏ –≤–∫–ª–∞–¥–æ–∫ –Ω–µ—Ç, –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ "ul#simple-episodes-tabs"
                if not season_ids:
                    tabs2 = soup.select("#simple-episodes-tabs li")
                    for t in tabs2:
                        sid = t.get("data-id") # –¢—É—Ç ID —Å–µ–∑–æ–Ω–∞ –±—ã–≤–∞–µ—Ç –≤ data-id
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ ID –ø–æ—Å—Ç–∞ (ID —Å–µ–∑–æ–Ω–∞ –æ–±—ã—á–Ω–æ –º–∞–ª–µ–Ω—å–∫–∏–π)
                        if sid and len(str(sid)) < 5: 
                            season_ids.append(sid)

                # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
                season_ids = sorted(list(set(season_ids)), key=lambda x: int(x) if x.isdigit() else 0)

                if season_ids:
                    print(f"üìã –ù–∞—à–µ–ª ID —Å–µ–∑–æ–Ω–æ–≤: {season_ids}")
                    for season_id in season_ids:
                        print(f"   ‚¨á –ö–∞—á–∞—é —Å–µ–∑–æ–Ω {season_id}...")
                        payload = {
                            "id": post_id, 
                            "translator_id": translator_id if translator_id else "238",
                            "season": season_id,
                            "action": "get_episodes"
                        }
                        try:
                            r_ajax = self.session.post(f"{self.origin}/ajax/get_cdn_series/", data=payload)
                            if r_ajax.json().get('success'):
                                html = r_ajax.json().get('seasons') or r_ajax.json().get('episodes')
                                season_data = self._parse_html_list(html)
                                for s, eps in season_data.items():
                                    if s not in player_seasons: player_seasons[s] = []
                                    player_seasons[s].extend(eps)
                        except: pass
                        time.sleep(0.05)
                else:
                    print("üöÄ –í–∫–ª–∞–¥–æ–∫ –Ω–µ—Ç, –∫–∞—á–∞—é –≤—Å—ë —Å—Ä–∞–∑—É...")
                    payload = {
                        "id": post_id, 
                        "translator_id": translator_id if translator_id else "238",
                        "action": "get_episodes"
                    }
                    try:
                        r_ajax = self.session.post(f"{self.origin}/ajax/get_cdn_series/", data=payload)
                        data = r_ajax.json()
                        if data.get('success'):
                            html = data.get('seasons') or data.get('episodes')
                            player_seasons = self._parse_html_list(html)
                    except: pass

            # –§–æ–ª–±–µ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É (–µ—Å–ª–∏ API –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª)
            if not player_seasons:
                print("‚ö†Ô∏è API –ø—É—Å—Ç, –±–µ—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—É...")
                player_seasons = self._parse_html_list(r.text)

            # 3. –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï
            final_seasons = player_seasons.copy()
            
            # –ï—Å–ª–∏ –≤ –ø–ª–µ–µ—Ä–µ –ø—É—Å—Ç–æ, –±–µ—Ä–µ–º —Ç–∞–±–ª–∏—Ü—É (–Ω–æ —Ç–∞–º —É–∂–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã –±—É–¥—É—â–∏–µ —Å–µ—Ä–∏–∏)
            if not final_seasons:
                final_seasons = table_seasons
            elif table_seasons:
                print("üîÑ –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å —Ç–∞–±–ª–∏—Ü–µ–π...")
                for s_id, t_eps in table_seasons.items():
                    # –ï—Å–ª–∏ —Å–µ–∑–æ–Ω–∞ –Ω–µ—Ç –≤ –ø–ª–µ–µ—Ä–µ - –¥–æ–±–∞–≤–ª—è–µ–º –∏–∑ —Ç–∞–±–ª–∏—Ü—ã
                    if s_id not in final_seasons:
                        final_seasons[s_id] = t_eps
                        continue
                    
                    # –ï—Å–ª–∏ —Å–µ–∑–æ–Ω –µ—Å—Ç—å - —Å–ª–∏–≤–∞–µ–º
                    for t_ep in t_eps:
                        found = False
                        for p_ep in final_seasons[s_id]:
                            if p_ep['episode'] == t_ep['episode']:
                                found = True
                                if t_ep['watched']: p_ep['watched'] = True
                                if not p_ep['global_id']: p_ep['global_id'] = t_ep['global_id']
                                break
                        # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑ —Ç–∞–±–ª–∏—Ü—ã, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ–π —Å–µ—Ä–∏–∏ –Ω–µ—Ç –≤ –ø–ª–µ–µ—Ä–µ
                        # (–±–ª–∞–≥–æ–¥–∞—Ä—è —Ñ–∏–ª—å—Ç—Ä—É –≤ _parse_schedule_table —Å—é–¥–∞ –Ω–µ –ø–æ–ø–∞–¥—É—Ç –±—É–¥—É—â–∏–µ —Å–µ—Ä–∏–∏ –±–µ–∑ ID)
                        if not found:
                             final_seasons[s_id].append(t_ep)

            if final_seasons:
                return {"seasons": final_seasons, "poster": hq_poster, "post_id": post_id}
            
            return {"error": "–ù–µ—Ç —Å–µ—Ä–∏–π", "poster": hq_poster, "post_id": post_id}

        except Exception as e:
            return {"error": str(e)}

    # –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    def get_category_items(self, cat_id):
        if not self.auth(): return []
        try:
            r = self.session.get(f"{self.origin}/favorites/{cat_id}/")
            soup = BeautifulSoup(r.text, 'html.parser')
            items = []
            for item in soup.find_all(class_="b-content__inline_item"):
                try:
                    link = item.find(class_="b-content__inline_item-link").find("a")
                    img = item.find(class_="b-content__inline_item-cover").find("img")
                    status = item.find(class_="info")
                    items.append({
                        "id": item.get("data-id"),
                        "title": link.text.strip(),
                        "url": link.get("href"),
                        "poster": img.get("src") if img else "",
                        "status": status.text.strip() if status else ""
                    })
                except: continue
            return items
        except: return []

    def search(self, query):
        if not self.auth(): return []
        try:
            r = self.session.post(f"{self.origin}/engine/ajax/search.php", data={"q": query})
            soup = BeautifulSoup(r.content, 'html.parser')
            results = []
            for item in soup.select('.b-search__section_list li'):
                try:
                    link = item.find('a')
                    title = item.find('span', class_='enty').get_text().strip()
                    url = link.attrs['href']
                    match = re.search(r'/(\d+)-', url)
                    if match:
                        results.append({
                            "id": match.group(1),
                            "title": title, "url": url
                        })
                except: continue
            return results
        except: return []

    def add_favorite(self, post_id, cat_id):
        if not self.auth(): return False
        try:
            r = self.session.post(f"{self.origin}/ajax/favorites/", data={
                "post_id": post_id, "cat_id": cat_id, "action": "add_post"
            })
            return r.json().get('success', False)
        except: return False

    def toggle_watch(self, global_id):
        if not self.auth(): return False
        try:
            r = self.session.post(f"{self.origin}/engine/ajax/schedule_watched.php", data={"id": global_id})
            return r.status_code == 200
        except: return False

client = RezkaClient()